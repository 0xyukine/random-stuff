from itertools import combinations
import matplotlib.pyplot as plt
import networkx as nx
import string
import json
import ast
import os

"""
### uncomment if executing in google colab
!pip install 'scipy>=1.8'
!pip install 'networkx<2.7'
"""

def create_item_list(filename):
	"""
	Creates a list of lists of sentences and words respectively. Reads in a text file, removes non alpha characters,
	barring spaces and periods as they're used to split the text

	Args:
		filename (string): location of the text file to be used

	Returns:
		list: A list of sentences which have further been split into a lists of words
	"""

	with open(filename, 'r') as file:
		text = file.read()
	for y in text:
		if 65 <= ord(y) <= 90 or 97 <= ord(y) <= 122 or ord(y) == 32 or y == ".":
			pass
		else:
			text = text.replace(y, "")
	text = text.split(".")
	for x,s in enumerate(text):
		text[x] = s.strip().split(" ")
	print(text)
	return text

def preprocess(filename):
	"""
	Reads in lists from a text file while casting them as pythonic lists and appends them to a list

	Args:
		filename (string): location of the text file to be used

	Returns:
		list: A list of lists
	"""

	item_list = []
	with open(filename, "r") as file:
		for line in file:
			item_list.append(ast.literal_eval(line))
	return item_list

def create_pairs(item_list):
	"""
	Takes in a list generated by either create_item_list or preprocess and creates a word co-occurence count from them.

	Args:
		item_list (list): a list of lists containing relevant items

	Returns:
		dictionary: A dictionary containing item combinatiosn in the form of {(x,y:z)} where
		x and y are items from the same list and z is the number of times the same combination has occured
	"""

	co_occurence = {}
	for l in item_list:
		pairs = combinations(l,2)
	
		for pair in pairs:
			pair = str(pair)
			if pair in co_occurence:
				co_occurence[pair] += 1
			else:
				co_occurence[pair] = 1
	return co_occurence

def save_pairs(pairs_dict):
	#Exports the co-occurences dictionary as a json
	with open('data.json', 'w') as fp:
		json.dump(pairs_dict, fp)

def load_pairs(filepath):
	#Imports the co-occurences json as a dictionary
	with open(filepath) as json_file:
		co_occurence = json.load(json_file)
	return co_occurence

def create_edges(pairs_dict):
	#Converts the co-occurnces into an edge graph
	G = nx.Graph()
	
	counta = 0
	countb = 0
	
	#Pairs are added into the graph using their count as the weight for edges
	#For loop currently excluded the lowest co-occurences as it's impractical
	#to graph everything and makes the process extremely ram heavy,
	#depending on the actual number of pairs
	for pair, count in pairs_dict.items():
		if count < 5:
			counta += 1
		else:
			pair = eval(pair)
			G.add_edge(pair[0], pair[1], weight=count)
			countb += 1
	print(f"Added: {countb}, Ignored: {counta}")

	return G

def draw_network(pairs_dict):
	#Runs create_edges() and draws the returned graph network
	G = create_edges(pairs_dict)
	plt.figure(figsize=(20,20))
	
	pos = nx.spring_layout(G, k=1, iterations=20)
	
	print("drawing nodes")
	nx.draw_networkx_nodes(G, pos)
	print("drawing edges")
	#nx.draw_networkx_edges(G, pos, width=[d['weight'] for (u,v,d) in G.edges(data=True)])
	#Currently removed edges being weighted by count as it makes cluttered graphs even more unreadable
	nx.draw_networkx_edges(G, pos, width=5)
	
	edge_labels = {(u, v): d['weight'] for (u,v,d) in G.edges(data=True)}
	
	print("drawing network")
	nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
	nx.draw_networkx_labels(G, pos)
	
	plt.savefig("graph.png")

create_item_list('book.txt')
print("starting")
#draw_network(create_pairs(preprocess('tags.txt')))
draw_network(create_pairs(create_item_list('book.txt')))